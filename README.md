# micrograd-mlp-from-scratch
This project demonstrates forward pass, backward pass, and gradient descent without using PyTorch or TensorFlow.
